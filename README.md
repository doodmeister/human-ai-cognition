# Human-AI Cognition

> **Where Memory Meets Meaning**  
> A modular framework for building a human-like AI system with memory, reasoning, and meta-cognitive abilities.

---

## ğŸ§  Overview

Human-AI Cognition is an open-source project to create a cognitive architecture that simulates aspects of human memory, attention, and thought.  
The system leverages **Short-Term Memory (STM)**, **Long-Term Memory (LTM)**, **Prospective Memory**, and Retrieval-Augmented Generation (**RAG**) to interact with a Large Language Model (Claude via AWS Bedrock).

The agent retrieves memories, builds context-rich prompts, and responds with reasoning augmented by its evolving memory.

---

## ğŸ“‚ Project Structure

```
human-ai-cognition/
â”œâ”€â”€ cognition/
â”‚   â”œâ”€â”€ cognitive_agent.py         # Main agent orchestration
â”‚   â”œâ”€â”€ rag_utils.py                # Prompt building utilities (RAG)
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ short_term_memory.py        # Short-term memory (STM)
â”‚   â”œâ”€â”€ long_term_memory.py         # Long-term memory (LTM - semantic focus)
â”‚   â”œâ”€â”€ prospective_memory.py       # Scheduled future tasks (reminders)
â”‚   â”œâ”€â”€ semantic_memory.py          # Semantic memory retrieval
â”‚   â”œâ”€â”€ episodic_memory.py          # Episodic memory placeholder
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ dpad_transformer.py         # Dynamic Predictive Attention Transformer (WIP)
â”œâ”€â”€ main.py                         # ğŸš€ Main launcher (new)
â”œâ”€â”€ terraform/                      # (optional) AWS deployment infrastructure
â”œâ”€â”€ README.md                       # (this file)
â””â”€â”€ requirements.txt                # Python dependencies
```

---

## ğŸš€ Quickstart Guide

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

You'll need:
- `boto3`
- `sentence-transformers`
- `torch`
- Any additional AWS authentication libraries if using Bedrock.

---

### 2. Set Environment Variables

You must have AWS credentials configured (`aws configure`) and access to:
- **AWS Bedrock Runtime** (Claude 3 model)
- (Optional) **S3** and **OpenSearch** if using memory consolidation features.

Set your environment variables (example):

```bash
export AWS_REGION=us-east-1
export S3_BUCKET=cognition-inputs
export BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0
```

---

### 3. Run the Cognitive Agent

```bash
python main.py
```

You should see:

```
ğŸ¤– Welcome to Human-AI Cognition Chatbot
Type 'exit' or 'quit' to end the conversation.
============================================================
You: 
```

Then you can start chatting!

The agent will:
- Retrieve memories from STM, LTM, and Reminders
- Build a prompt
- Send it to Claude on AWS Bedrock
- Save your conversation to STM for future use

---

## ğŸ§  How the Cognitive Loop Works

1. **User input** â†’ embedded into a vector
2. **STM and LTM** â†’ queried for relevant memories
3. **Reminders** â†’ checked
4. **Prompt** â†’ dynamically built (RAG style)
5. **Claude LLM** â†’ invoked via AWS Bedrock
6. **Reply** â†’ printed + conversation stored into STM
7. **Memory decay** â†’ simulated over time

---

## ğŸ›  Key Improvements Over Earlier Versions

- ğŸ“š **Short-Term Memory** now supports `query()` and `insert()`
- ğŸ“š **Long-Term Memory** combines semantic memory retrieval
- ğŸ§¹ **Prompt Building** now safely handles dicts or strings
- ğŸš€ **Bedrock Integration** uses `invoke_model()` properly (no `.converse()`)
- ğŸ§  **Embedder Class** optimizes memory vector embedding
- ğŸ”¥ **CognitiveAgent** orchestrates everything cleanly
- ğŸ§¹ **Main CLI (`main.py`)** provides robust user interaction
- ğŸ“„ **Improved Documentation** (this README!)

---

## ğŸ“… Future Enhancements (Roadmap)

- Dream-state consolidation of STM to LTM
- Fatigue, attention, and emotional state modeling
- Episodic + semantic memory blending
- Memory decay models based on time + relevance
- Context prioritization (importance scoring)
- Real-time sensory input buffering
- OpenSearch vector database for LTM (optional upgrade)
- Full web-based interactive UI (Phase 2)

---

## ğŸ¤ Contributing

Contributions are welcome!  
Planned areas:
- Improving memory querying (semantic search)
- Better meta-cognition feedback loops
- Dream-state consolidation improvements
- More biologically-plausible memory decay models

---

## ğŸ“œ License

[MIT License](LICENSE)

---

## âœ¨ Credits

- Built with passion for human cognition, AI architecture, and open-source spirit.
- Thanks to AWS Bedrock, SentenceTransformers, and all contributors pushing the boundary of cognitive AI.

---

> "Memory isn't just storage. It's meaning. It's life." ğŸ§ 